
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
import pandas as pd
import zipfile
import io

# Define the path to your ZIP file
zip_file_path = '/kaggle/input/tmdb-movie-metadata/tmdb_5000_movies.csv.zip'
# Kaggle often bundles the two CSVs into a single ZIP,
# but sometimes they are provided as separate zips in the same directory.
# Let's assume for a moment they are in *separate* zips
# if they were in the same ZIP, the error would mean your path is likely incorrect,
# or you're trying to read a *folder* that contains multiple zips.

# Given your error message: "Multiple files found in ZIP file. Only one file per ZIP:
# ['tmdb_5000_movies.csv', 'tmdb_5000_credits.csv']"
# This implies that the file you're trying to read, e.g.,
# '/kaggle/input/tmdb-movie-metadata/tmdb_5000_movies.csv.zip'
# *actually contains both* 'tmdb_5000_movies.csv' AND 'tmdb_5000_credits.csv' within it.

# Let's adjust the zip_file_path to reflect the likely structure where *both* CSVs are in one ZIP
# A common Kaggle setup for this dataset is a single folder `tmdb-movie-metadata`
# which then contains the two `.csv` files directly, not within an outer `.zip`.
# However, if your data *is* structured as a single ZIP containing both,
# you'd need the following:

# Assume the actual ZIP file name is 'tmdb_5000_metadata.zip'
# (You might need to verify the exact name of the ZIP file on Kaggle)
# For example, if the entire dataset is zipped as 'tmdb_movie_metadata.zip'
actual_zip_file_path = '/content/tmdb_5000_credits.csv (1).zip' # This is a common pattern on Kaggle

# If the Kaggle dataset is structured such that you access the CSVs directly,
# without an explicit .zip extension, then your original code was fine and the error
# might come from a different context (e.g., if you manually zipped them up later).

# Let's go with the most common scenario for *your error message*:
# A single ZIP file named (for example) 'tmdb_movie_metadata.zip' contains both CSVs.

# Corrected code to read from a single ZIP file containing both CSVs:
with zipfile.ZipFile(actual_zip_file_path, 'r') as z:
    # Read 'tmdb_5000_movies.csv' from the zip
    with z.open('tmdb_5000_movies.csv') as f_movies:
        movies = pd.read_csv(io.BytesIO(f_movies.read())) # Use io.BytesIO for pandas to read it

    # Read 'tmdb_5000_credits.csv' from the zip
    with z.open('tmdb_5000_credits.csv') as f_credits:
        credits = pd.read_csv(io.BytesIO(f_credits.read()))

# Display the first two rows to confirm
print("Movies DataFrame:")
print(movies.head(2))
print("\nCredits DataFrame:")
print(credits.head(2))
import ast
def convert(text):
    L = []
    for i in ast.literal_eval(text):
        L.append(i['name'])
    return L

    movies.dropna(inplace=True)
movies['genres'] = movies['genres'].apply(convert)
movies.head()
movies['keywords'] = movies['keywords'].apply(convert)
movies.head()



import ast

import ast
ast.literal_eval('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

	movies = movies.merge(credits,on='title')
movies.head()

	movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]
movies.head()

	import ast
def convert(text):
    L = []
    for i in ast.literal_eval(text):
        L.append(i['name'])
    return L
    movies.dropna(inplace=True)
movies['genres'] = movies['genres'].apply(convert)
movies.head()

movies['keywords'] = movies['keywords'].apply(convert)
movies.head()

import ast
ast.literal_eval('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

def convert3(text):
    L = []
    counter = 0
    for i in ast.literal_eval(text):
        if counter < 3:
            L.append(i['name'])
        counter+=1
    return L

movies['cast'] = movies['cast'].apply(convert)
movies.head()

	movies['cast'] = movies['cast'].apply(lambda x:x[0:3])

	def fetch_director(text):
    L = []
    for i in ast.literal_eval(text):
        if i['job'] == 'Director':
            L.append(i['name'])
    return L

	import ast

def fetch_director(text):
    L = []
    if isinstance(text, str): # Ensure it's a string before attempting literal_eval
        try:
            list_of_dicts = ast.literal_eval(text)
            for i in list_of_dicts:
                if i['job'] == 'Director':
                    L.append(i['name'])
                    break # Assuming only one director per movie for simplicity
        except (ValueError, SyntaxError):
            return [] # Return empty list if parsing fails
    return L
    movies['crew'] = movies['crew'].apply(fetch_director)

def collapse(L):
    L1 = []
    for i in L:
        L1.append(i.replace(" ",""))
    return L1
movies['cast'] = movies['cast'].apply(collapse)
movies['crew'] = movies['crew'].apply(collapse)
movies['genres'] = movies['genres'].apply(collapse)
movies['keywords'] = movies['keywords'].apply(collapse)
movies.head(10)


import pandas as pd

# Assuming 'movies' DataFrame is already loaded and previous transformations are done
# (e.g., 'genres', 'keywords', 'cast', 'crew' are already processed into lists/strings)

# --- Fix for the AttributeError ---
# 1. Fill NaN values in 'overview' with an empty string
movies['overview'] = movies['overview'].fillna('')

# 2. Now apply split to the 'overview' column
movies['overview'] = movies['overview'].apply(lambda x: x.split())

# --- Continue with the rest of your code ---
# Ensure other columns are also in a suitable format (e.g., lists of strings or strings)
# before concatenation. If 'genres', 'keywords', 'cast', 'crew' are not yet lists of strings,
# they might need similar pre-processing.

# Example if other columns are still JSON strings or potentially contain NaNs:
# (You might have already done this with your 'convert' functions)
# movies['genres'] = movies['genres'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)] if isinstance(x, str) else [])
# movies['keywords'] = movies['keywords'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)] if isinstance(x, str) else [])
# (assuming 'cast' and 'crew' are already processed to lists of names by your `convert3` and `fetch_director` functions)

# Concatenate the lists
movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

# Drop the original columns
new = movies.drop(columns=['overview', 'genres', 'keywords', 'cast', 'crew'])

print(new.head())
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000,stop_words='english')

vector = cv.fit_transform(new['tags']).toarray()
vector.shape

	from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(vector)
similarity
new[new['title'] == 'The Lego Movie'].index[0]

def recommend(movie):
    index = new[new['title'] == movie].index[0]
    distances = sorted(list(enumerate(similarity[index])),reverse=True,key = lambda x: x[1])
    for i in distances[1:6]:
        print(new.iloc[i[0]].title)

recommend('')

import pickle
pickle.dump(new,open('movie_list.pkl','wb'))
pickle.dump(similarity,open('similarity.pkl','wb'))
